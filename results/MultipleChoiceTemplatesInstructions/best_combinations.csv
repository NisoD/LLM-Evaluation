model,dataset,shuffle_choices,choices_separator,enumerator,accuracy
Mistral-7B-Instruct-v0.2,mmlu.abstract_algebra,False,; ,roman,
Mistral-7B-Instruct-v0.2,mmlu.medical_genetics,True,; ,numbers,
Mistral-7B-Instruct-v0.2,mmlu.high_school_geography,True,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.college_physics,True,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.nutrition,False,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.human_aging,False,; ,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.electrical_engineering,False, | ,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.professional_law,True, or ,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.high_school_biology,True,\n,capitals,
Mistral-7B-Instruct-v0.2,mmlu.conceptual_physics,False,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.security_studies,False,\s,capitals,
Mistral-7B-Instruct-v0.2,mmlu.high_school_microeconomics,True,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.high_school_macroeconomics,True,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.moral_disputes,False, | ,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.high_school_computer_science,False,\n,numbers,
Mistral-7B-Instruct-v0.2,mmlu.international_law,False, OR ,numbers,
Mistral-7B-Instruct-v0.2,mmlu.high_school_psychology,True,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.prehistory,False,", ",capitals,
Mistral-7B-Instruct-v0.2,mmlu.high_school_us_history,False,\n,numbers,
Mistral-7B-Instruct-v0.2,mmlu.computer_security,False, or ,numbers,
Mistral-7B-Instruct-v0.2,mmlu.management,True,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.professional_psychology,False,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.logical_fallacies,False,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.college_medicine,False,\s,capitals,
Mistral-7B-Instruct-v0.2,mmlu.formal_logic,True,\n,capitals,
Mistral-7B-Instruct-v0.2,mmlu.us_foreign_policy,False,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.econometrics,True, OR ,numbers,
Mistral-7B-Instruct-v0.2,mmlu.virology,False,\n,capitals,
Mistral-7B-Instruct-v0.2,mmlu.sociology,False,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.college_chemistry,True,", ",lowercase,
Mistral-7B-Instruct-v0.2,mmlu.anatomy,False, | ,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.machine_learning,False, OR ,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.high_school_chemistry,False,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.clinical_knowledge,False,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.miscellaneous,False,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.high_school_statistics,True,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.college_computer_science,False,\n,capitals,
Mistral-7B-Instruct-v0.2,mmlu.philosophy,False,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.elementary_mathematics,False,", ",lowercase,
Mistral-7B-Instruct-v0.2,mmlu.astronomy,True,\n,numbers,
Mistral-7B-Instruct-v0.2,mmlu.professional_medicine,False,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.high_school_government_and_politics,True,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.high_school_european_history,False,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.marketing,False,; ,capitals,
Mistral-7B-Instruct-v0.2,mmlu.global_facts,False, or ,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.high_school_world_history,True,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.high_school_mathematics,False,; ,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.moral_scenarios,False, or ,capitals,
Mistral-7B-Instruct-v0.2,mmlu.high_school_physics,True, or ,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.business_ethics,False,\n,numbers,
Mistral-7B-Instruct-v0.2,mmlu.jurisprudence,True,\n,capitals,
Mistral-7B-Instruct-v0.2,mmlu.professional_accounting,True,; ,capitals,
Mistral-7B-Instruct-v0.2,mmlu.human_sexuality,False,\n,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.college_biology,False,; ,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.college_mathematics,True,\s,lowercase,
Mistral-7B-Instruct-v0.2,mmlu.public_relations,False,\n,capitals,
Mistral-7B-Instruct-v0.2,mmlu.world_religions,False,\n,numbers,
