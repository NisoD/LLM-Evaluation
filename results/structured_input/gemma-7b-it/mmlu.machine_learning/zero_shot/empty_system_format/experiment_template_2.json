{"card": "cards.mmlu.machine_learning", "template_name": "template_2", "model_name": "google/gemma-7b-it", "system_format": "empty_system_format", "max_instances": 100, "num_demos": 0, "demos_pool_size": 10, "results": {"test": [{"Index": 0, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: Statement 1| Linear regression estimator has the smallest variance among all unbiased estimators. Statement 2| The coefficients \u03b1 assigned to the classifiers assembled by AdaBoost are always non-negative. Choices: A. True, True\nB. False, False\nC. True, False\nD. False, True Answer:\n", "Result": "The answer to this question is A.\n\n**Explanation:**\nThe statement \"Linear regression estimator", "GroundTruth": "D. False, True"}, {"Index": 1, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: Statement 1| RoBERTa pretrains on a corpus that is approximate 10x larger than the corpus BERT pretrained on. Statement 2| ResNeXts in 2018 usually used tanh activation functions. Choices: A. True, True\nB. False, False\nC. True, False\nD. False, True Answer:\n", "Result": "The answer to this question is A.\n\n**Explanation:**\nRoBERTa is a pre", "GroundTruth": "C. True, False"}, {"Index": 2, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: Statement 1| Support vector machines, like logistic regression models, give a probability distribution over the possible labels given an input example. Statement 2| We would expect the support vectors to remain the same in general as we move from a linear kernel to higher order polynomial kernels. Choices: A. True, True\nB. False, False\nC. True, False\nD. False, True Answer:\n", "Result": "The answer to this question is C.\n\n**Explanation:**\n\nSupport vector machines (SVMs", "GroundTruth": "B. False, False"}, {"Index": 3, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: A machine learning problem involves four attributes plus a class. The attributes have 3, 2, 2, and 2 possible values each. The class has 3 possible values. How many maximum possible different examples are there? Choices: A. 12\nB. 24\nC. 48\nD. 72 Answer:\n", "Result": "The answer is B.\n\nThe number of possible examples for each attribute is 3, ", "GroundTruth": "D. 72"}, {"Index": 4, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: As of 2020, which architecture is best for classifying high-resolution images? Choices: A. convolutional networks\nB. graph networks\nC. fully connected networks\nD. RBF networks Answer:\n", "Result": "A\n\nThe answer is A. Convolutional networks are best for classifying high-resolution images because", "GroundTruth": "A. convolutional networks"}, {"Index": 5, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: Statement 1| The log-likelihood of the data will always increase through successive iterations of the expectation maximation algorithm. Statement 2| One disadvantage of Q-learning is that it can only be used when the learner has prior knowledge of how its actions affect its environment. Choices: A. True, True\nB. False, False\nC. True, False\nD. False, True Answer:\n", "Result": "The answer to this question is C. True, False.\n\nThe log-likelihood of the", "GroundTruth": "B. False, False"}, {"Index": 6, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: Let us say that we have computed the gradient of our cost function and stored it in a vector g. What is the cost of one gradient descent update given the gradient? Choices: A. O(D)\nB. O(N)\nC. O(ND)\nD. O(ND^2) Answer:\n", "Result": "The cost of one gradient descent update is O(D), where D is the number of parameters", "GroundTruth": "A. O(D)"}, {"Index": 7, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: Statement 1| For a continuous random variable x and its probability distribution function p(x), it holds that 0 \u2264 p(x) \u2264 1 for all x. Statement 2| Decision tree is learned by minimizing information gain. Choices: A. True, True\nB. False, False\nC. True, False\nD. False, True Answer:\n", "Result": "The answer is A.\n\nExplanation:\nThe statement \"0 \u2264 p(x) \u2264", "GroundTruth": "B. False, False"}, {"Index": 8, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: Consider the Bayesian network given below. How many independent parameters are needed for this Bayesian Network H -> U <- P <- W? Choices: A. 2\nB. 4\nC. 8\nD. 16 Answer:\n", "Result": "The Bayesian network H -> U <- P <- W has a total of 4 independent parameters.", "GroundTruth": "C. 8"}, {"Index": 9, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: As the number of training examples goes to infinity, your model trained on that data will have: Choices: A. Lower variance\nB. Higher variance\nC. Same variance\nD. None of the above Answer:\n", "Result": "The answer is A.\n\nExplanation:\nAs the number of training examples goes to infinity,", "GroundTruth": "A. Lower variance"}, {"Index": 10, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: Statement 1| The set of all rectangles in the 2D plane (which includes non axisaligned rectangles) can shatter a set of 5 points. Statement 2| The VC-dimension of k-Nearest Neighbour classifier when k = 1 is infinite. Choices: A. True, True\nB. False, False\nC. True, False\nD. False, True Answer:\n", "Result": "The answer to this question is A.\n\n**Explanation:**\nThe statement \"The set of", "GroundTruth": "A. True, True"}, {"Index": 11, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: _ refers to a model that can neither model the training data nor generalize to new data. Choices: A. good fitting\nB. overfitting\nC. underfitting\nD. all of the above Answer:\n", "Result": "_\n\n**Explanation:**\n\nThe answer is C. Underfitting refers to a model that cannot", "GroundTruth": "C. underfitting"}, {"Index": 12, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: Statement 1| The F1 score can be especially useful for datasets with class high imbalance. Statement 2| The area under the ROC curve is one of the main metrics used to assess anomaly detectors. Choices: A. True, True\nB. False, False\nC. True, False\nD. False, True Answer:\n", "Result": "The answer to this question is A.\n\nThe F1 score is a metric that measures the", "GroundTruth": "A. True, True"}, {"Index": 13, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: Statement 1| The back-propagation algorithm learns a globally optimal neural network with hidden layers. Statement 2| The VC dimension of a line should be at most 2, since I can find at least one case of 3 points that cannot be shattered by any line. Choices: A. True, True\nB. False, False\nC. True, False\nD. False, True Answer:\n", "Result": "The answer to this question is C.\n\n**Explanation:**\n\n**Statement 1:** The", "GroundTruth": "B. False, False"}, {"Index": 14, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: High entropy means that the partitions in classification are Choices: A. pure\nB. not pure\nC. useful\nD. useless Answer:\n", "Result": "The entropy of a system is a measure of its randomness. High entropy means that the system is", "GroundTruth": "B. not pure"}, {"Index": 15, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: Statement 1| Layer Normalization is used in the original ResNet paper, not Batch Normalization. Statement 2| DCGANs use self-attention to stabilize training. Choices: A. True, True\nB. False, False\nC. True, False\nD. False, True Answer:\n", "Result": "The answer to this question is C. True, False.\n\n**Explanation:**\nStatement ", "GroundTruth": "B. False, False"}, {"Index": 16, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: In building a linear regression model for a particular data set, you observe the coefficient of one of the features having a relatively high negative value. This suggests that Choices: A. This feature has a strong effect on the model (should be retained)\nB. This feature does not have a strong effect on the model (should be ignored)\nC. It is not possible to comment on the importance of this feature without additional information\nD. Nothing can be determined. Answer:\n", "Result": "The answer to this question is B.\n\n**Explanation:**\nIn linear regression, the coefficient", "GroundTruth": "C. It is not possible to comment on the importance of this feature without additional information"}, {"Index": 17, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: For a neural network, which one of these structural assumptions is the one that most affects the trade-off between underfitting (i.e. a high bias model) and overfitting (i.e. a high variance model): Choices: A. The number of hidden nodes\nB. The learning rate\nC. The initial choice of weights\nD. The use of a constant-term unit input Answer:\n", "Result": "The answer is A.\n\nThe number of hidden nodes is the most important factor affecting the trade", "GroundTruth": "A. The number of hidden nodes"}, {"Index": 18, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: For polynomial regression, which one of these structural assumptions is the one that most affects the trade-off between underfitting and overfitting: Choices: A. The polynomial degree\nB. Whether we learn the weights by matrix inversion or gradient descent\nC. The assumed variance of the Gaussian noise\nD. The use of a constant-term unit input Answer:\n", "Result": "**Explanation:** [explanation]\n\n**Note:** This template is for a question and answer format", "GroundTruth": "A. The polynomial degree"}, {"Index": 19, "Instance": "Question: [question] Choices: [choices] Answer: [answer]\nQuestion: Statement 1| As of 2020, some models attain greater than 98% accuracy on CIFAR-10. Statement 2| The original ResNets were not optimized with the Adam optimizer. Choices: A. True, True\nB. False, False\nC. True, False\nD. False, True Answer:\n", "Result": "The answer to this question is C. True, False.\n\n**Explanation:**\n\nStatement ", "GroundTruth": "A. True, True"}]}}