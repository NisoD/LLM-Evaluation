template_name,card,system_format,num_demos,demos_pool_size,max_instances,accuracy,score,score_name,accuracy_ci_low,accuracy_ci_high,score_ci_low,score_ci_high,number_of_instances
template_0,cards.mmlu.high_school_world_history,empty_system_format,0,10,14000,0.502,0.502,accuracy,0.439,0.565,0.439,0.565,237
template_1,cards.mmlu.high_school_world_history,empty_system_format,0,10,14000,0.473,0.473,accuracy,0.409,0.537,0.409,0.537,237
template_2,cards.mmlu.high_school_world_history,empty_system_format,0,10,14000,0.557,0.557,accuracy,0.489,0.620,0.489,0.620,237
template_3,cards.mmlu.high_school_world_history,empty_system_format,0,10,14000,0.549,0.549,accuracy,0.488,0.616,0.488,0.616,237
template_4,cards.mmlu.high_school_world_history,empty_system_format,0,10,14000,0.494,0.494,accuracy,0.430,0.561,0.430,0.561,237
template_5,cards.mmlu.high_school_world_history,empty_system_format,0,10,14000,0.456,0.456,accuracy,0.392,0.520,0.392,0.520,237
template_6,cards.mmlu.high_school_world_history,empty_system_format,0,10,14000,0.459,0.459,accuracy,0.378,0.548,0.378,0.548,135
template_28,cards.mmlu.high_school_world_history,empty_system_format,0,10,14000,0.608,0.608,accuracy,0.540,0.667,0.540,0.667,237
template_29,cards.mmlu.high_school_world_history,empty_system_format,0,10,14000,0.570,0.570,accuracy,0.506,0.633,0.506,0.633,237
template_30,cards.mmlu.high_school_world_history,empty_system_format,0,10,14000,0.616,0.616,accuracy,0.549,0.675,0.549,0.675,237
template_31,cards.mmlu.high_school_world_history,empty_system_format,0,10,14000,0.561,0.561,accuracy,0.495,0.622,0.495,0.622,237
template_32,cards.mmlu.high_school_world_history,empty_system_format,0,10,14000,0.599,0.599,accuracy,0.540,0.662,0.540,0.662,237
template_33,cards.mmlu.high_school_world_history,empty_system_format,0,10,14000,0.586,0.586,accuracy,0.523,0.646,0.523,0.646,237
template_34,cards.mmlu.high_school_world_history,empty_system_format,0,10,14000,0.636,0.636,accuracy,0.536,0.718,0.536,0.718,110
